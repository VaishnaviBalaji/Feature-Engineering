{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha_ec_0</th>\n",
       "      <th>alpha_ec_1</th>\n",
       "      <th>alpha_ec_2</th>\n",
       "      <th>alpha_ec_3</th>\n",
       "      <th>alpha_ec_4</th>\n",
       "      <th>alpha_ec_5</th>\n",
       "      <th>alpha_ec_6</th>\n",
       "      <th>alpha_ec_7</th>\n",
       "      <th>alpha_ec_8</th>\n",
       "      <th>alpha_ec_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_theta_39</th>\n",
       "      <th>ratio_theta_40</th>\n",
       "      <th>ratio_theta_41</th>\n",
       "      <th>ratio_theta_42</th>\n",
       "      <th>ratio_theta_43</th>\n",
       "      <th>ratio_theta_44</th>\n",
       "      <th>ratio_theta_45</th>\n",
       "      <th>ratio_theta_46</th>\n",
       "      <th>ratio_theta_47</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.11184</td>\n",
       "      <td>0.12387</td>\n",
       "      <td>0.12858</td>\n",
       "      <td>0.11324</td>\n",
       "      <td>0.10571</td>\n",
       "      <td>0.10690</td>\n",
       "      <td>0.10756</td>\n",
       "      <td>0.11064</td>\n",
       "      <td>0.10875</td>\n",
       "      <td>0.15893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.73870</td>\n",
       "      <td>0.58709</td>\n",
       "      <td>0.55198</td>\n",
       "      <td>0.54811</td>\n",
       "      <td>0.57869</td>\n",
       "      <td>0.59345</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>0.56294</td>\n",
       "      <td>1.01440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.29834</td>\n",
       "      <td>0.26881</td>\n",
       "      <td>0.26239</td>\n",
       "      <td>0.38009</td>\n",
       "      <td>0.34358</td>\n",
       "      <td>0.28500</td>\n",
       "      <td>0.24791</td>\n",
       "      <td>0.25033</td>\n",
       "      <td>0.26047</td>\n",
       "      <td>0.26016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32788</td>\n",
       "      <td>0.43164</td>\n",
       "      <td>0.49603</td>\n",
       "      <td>0.40680</td>\n",
       "      <td>0.31283</td>\n",
       "      <td>0.66352</td>\n",
       "      <td>0.58386</td>\n",
       "      <td>0.46658</td>\n",
       "      <td>0.74867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.36912</td>\n",
       "      <td>0.39587</td>\n",
       "      <td>0.38999</td>\n",
       "      <td>0.25772</td>\n",
       "      <td>0.40554</td>\n",
       "      <td>0.44199</td>\n",
       "      <td>0.44004</td>\n",
       "      <td>0.39947</td>\n",
       "      <td>0.31546</td>\n",
       "      <td>0.28348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.86506</td>\n",
       "      <td>1.09310</td>\n",
       "      <td>0.31759</td>\n",
       "      <td>0.36353</td>\n",
       "      <td>0.50553</td>\n",
       "      <td>0.33478</td>\n",
       "      <td>0.49383</td>\n",
       "      <td>0.62363</td>\n",
       "      <td>0.61417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.76120</td>\n",
       "      <td>0.77726</td>\n",
       "      <td>0.77042</td>\n",
       "      <td>0.60161</td>\n",
       "      <td>0.70183</td>\n",
       "      <td>0.72725</td>\n",
       "      <td>0.76245</td>\n",
       "      <td>0.78904</td>\n",
       "      <td>0.72984</td>\n",
       "      <td>0.52236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25090</td>\n",
       "      <td>0.43196</td>\n",
       "      <td>0.71301</td>\n",
       "      <td>0.53340</td>\n",
       "      <td>0.28528</td>\n",
       "      <td>0.68135</td>\n",
       "      <td>0.66315</td>\n",
       "      <td>0.25250</td>\n",
       "      <td>0.85448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.16770</td>\n",
       "      <td>0.15146</td>\n",
       "      <td>0.14714</td>\n",
       "      <td>0.15728</td>\n",
       "      <td>0.14965</td>\n",
       "      <td>0.14154</td>\n",
       "      <td>0.13228</td>\n",
       "      <td>0.12760</td>\n",
       "      <td>0.14351</td>\n",
       "      <td>0.17252</td>\n",
       "      <td>...</td>\n",
       "      <td>1.73190</td>\n",
       "      <td>1.24420</td>\n",
       "      <td>2.76220</td>\n",
       "      <td>3.00930</td>\n",
       "      <td>2.43520</td>\n",
       "      <td>2.53070</td>\n",
       "      <td>2.58470</td>\n",
       "      <td>2.00770</td>\n",
       "      <td>2.29460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 433 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha_ec_0  alpha_ec_1  alpha_ec_2  alpha_ec_3  alpha_ec_4  alpha_ec_5  \\\n",
       "0     0.11184     0.12387     0.12858     0.11324     0.10571     0.10690   \n",
       "1     0.29834     0.26881     0.26239     0.38009     0.34358     0.28500   \n",
       "2     0.36912     0.39587     0.38999     0.25772     0.40554     0.44199   \n",
       "3     0.76120     0.77726     0.77042     0.60161     0.70183     0.72725   \n",
       "4     0.16770     0.15146     0.14714     0.15728     0.14965     0.14154   \n",
       "\n",
       "   alpha_ec_6  alpha_ec_7  alpha_ec_8  alpha_ec_9  ...  ratio_theta_39  \\\n",
       "0     0.10756     0.11064     0.10875     0.15893  ...         0.73870   \n",
       "1     0.24791     0.25033     0.26047     0.26016  ...         0.32788   \n",
       "2     0.44004     0.39947     0.31546     0.28348  ...         0.86506   \n",
       "3     0.76245     0.78904     0.72984     0.52236  ...         0.25090   \n",
       "4     0.13228     0.12760     0.14351     0.17252  ...         1.73190   \n",
       "\n",
       "   ratio_theta_40  ratio_theta_41  ratio_theta_42  ratio_theta_43  \\\n",
       "0         0.58709         0.55198         0.54811         0.57869   \n",
       "1         0.43164         0.49603         0.40680         0.31283   \n",
       "2         1.09310         0.31759         0.36353         0.50553   \n",
       "3         0.43196         0.71301         0.53340         0.28528   \n",
       "4         1.24420         2.76220         3.00930         2.43520   \n",
       "\n",
       "   ratio_theta_44  ratio_theta_45  ratio_theta_46  ratio_theta_47  labels  \n",
       "0         0.59345         0.60436         0.56294         1.01440       0  \n",
       "1         0.66352         0.58386         0.46658         0.74867       0  \n",
       "2         0.33478         0.49383         0.62363         0.61417       0  \n",
       "3         0.68135         0.66315         0.25250         0.85448       0  \n",
       "4         2.53070         2.58470         2.00770         2.29460       0  \n",
       "\n",
       "[5 rows x 433 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('spinal.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha_ec_0</th>\n",
       "      <th>alpha_ec_1</th>\n",
       "      <th>alpha_ec_2</th>\n",
       "      <th>alpha_ec_3</th>\n",
       "      <th>alpha_ec_4</th>\n",
       "      <th>alpha_ec_5</th>\n",
       "      <th>alpha_ec_6</th>\n",
       "      <th>alpha_ec_7</th>\n",
       "      <th>alpha_ec_8</th>\n",
       "      <th>alpha_ec_9</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_theta_39</th>\n",
       "      <th>ratio_theta_40</th>\n",
       "      <th>ratio_theta_41</th>\n",
       "      <th>ratio_theta_42</th>\n",
       "      <th>ratio_theta_43</th>\n",
       "      <th>ratio_theta_44</th>\n",
       "      <th>ratio_theta_45</th>\n",
       "      <th>ratio_theta_46</th>\n",
       "      <th>ratio_theta_47</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.403767</td>\n",
       "      <td>0.406051</td>\n",
       "      <td>0.404508</td>\n",
       "      <td>0.378024</td>\n",
       "      <td>0.370230</td>\n",
       "      <td>0.363051</td>\n",
       "      <td>0.363476</td>\n",
       "      <td>0.369076</td>\n",
       "      <td>0.377025</td>\n",
       "      <td>0.384056</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018505</td>\n",
       "      <td>0.987059</td>\n",
       "      <td>0.982096</td>\n",
       "      <td>1.037945</td>\n",
       "      <td>0.971646</td>\n",
       "      <td>0.988384</td>\n",
       "      <td>1.019272</td>\n",
       "      <td>0.969618</td>\n",
       "      <td>1.081742</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.212651</td>\n",
       "      <td>0.208703</td>\n",
       "      <td>0.203369</td>\n",
       "      <td>0.207096</td>\n",
       "      <td>0.194484</td>\n",
       "      <td>0.188324</td>\n",
       "      <td>0.186206</td>\n",
       "      <td>0.186509</td>\n",
       "      <td>0.188557</td>\n",
       "      <td>0.195015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786103</td>\n",
       "      <td>0.748024</td>\n",
       "      <td>0.774820</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.782806</td>\n",
       "      <td>0.736152</td>\n",
       "      <td>0.754223</td>\n",
       "      <td>0.766757</td>\n",
       "      <td>0.683975</td>\n",
       "      <td>0.498290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.045305</td>\n",
       "      <td>0.052493</td>\n",
       "      <td>0.064302</td>\n",
       "      <td>0.045197</td>\n",
       "      <td>0.052021</td>\n",
       "      <td>0.054035</td>\n",
       "      <td>0.058347</td>\n",
       "      <td>0.059784</td>\n",
       "      <td>0.066457</td>\n",
       "      <td>0.065896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150610</td>\n",
       "      <td>0.181840</td>\n",
       "      <td>0.156700</td>\n",
       "      <td>0.175150</td>\n",
       "      <td>0.129730</td>\n",
       "      <td>0.163480</td>\n",
       "      <td>0.221970</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.202360</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.240980</td>\n",
       "      <td>0.249482</td>\n",
       "      <td>0.258088</td>\n",
       "      <td>0.209325</td>\n",
       "      <td>0.209490</td>\n",
       "      <td>0.198185</td>\n",
       "      <td>0.205645</td>\n",
       "      <td>0.216885</td>\n",
       "      <td>0.219768</td>\n",
       "      <td>0.238817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567813</td>\n",
       "      <td>0.544520</td>\n",
       "      <td>0.478085</td>\n",
       "      <td>0.478295</td>\n",
       "      <td>0.502760</td>\n",
       "      <td>0.500135</td>\n",
       "      <td>0.539732</td>\n",
       "      <td>0.503913</td>\n",
       "      <td>0.619140</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.377190</td>\n",
       "      <td>0.384445</td>\n",
       "      <td>0.390135</td>\n",
       "      <td>0.358825</td>\n",
       "      <td>0.372940</td>\n",
       "      <td>0.360960</td>\n",
       "      <td>0.364725</td>\n",
       "      <td>0.370520</td>\n",
       "      <td>0.370055</td>\n",
       "      <td>0.359725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795555</td>\n",
       "      <td>0.833965</td>\n",
       "      <td>0.693510</td>\n",
       "      <td>0.788905</td>\n",
       "      <td>0.751085</td>\n",
       "      <td>0.740230</td>\n",
       "      <td>0.757965</td>\n",
       "      <td>0.733035</td>\n",
       "      <td>0.907780</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.540840</td>\n",
       "      <td>0.541517</td>\n",
       "      <td>0.544342</td>\n",
       "      <td>0.511320</td>\n",
       "      <td>0.503810</td>\n",
       "      <td>0.486232</td>\n",
       "      <td>0.484110</td>\n",
       "      <td>0.500715</td>\n",
       "      <td>0.504252</td>\n",
       "      <td>0.519500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.266450</td>\n",
       "      <td>1.170825</td>\n",
       "      <td>1.161300</td>\n",
       "      <td>1.311050</td>\n",
       "      <td>1.158325</td>\n",
       "      <td>1.161850</td>\n",
       "      <td>1.202875</td>\n",
       "      <td>1.097800</td>\n",
       "      <td>1.301550</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.991070</td>\n",
       "      <td>0.952930</td>\n",
       "      <td>0.950500</td>\n",
       "      <td>0.998370</td>\n",
       "      <td>0.914860</td>\n",
       "      <td>0.893100</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>0.847760</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>0.987760</td>\n",
       "      <td>...</td>\n",
       "      <td>6.624000</td>\n",
       "      <td>6.733600</td>\n",
       "      <td>4.496800</td>\n",
       "      <td>6.669300</td>\n",
       "      <td>5.561000</td>\n",
       "      <td>3.959300</td>\n",
       "      <td>4.450900</td>\n",
       "      <td>5.353900</td>\n",
       "      <td>5.352300</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 433 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alpha_ec_0  alpha_ec_1  alpha_ec_2  alpha_ec_3  alpha_ec_4  alpha_ec_5  \\\n",
       "count  180.000000  180.000000  180.000000  180.000000  180.000000  180.000000   \n",
       "mean     0.403767    0.406051    0.404508    0.378024    0.370230    0.363051   \n",
       "std      0.212651    0.208703    0.203369    0.207096    0.194484    0.188324   \n",
       "min      0.045305    0.052493    0.064302    0.045197    0.052021    0.054035   \n",
       "25%      0.240980    0.249482    0.258088    0.209325    0.209490    0.198185   \n",
       "50%      0.377190    0.384445    0.390135    0.358825    0.372940    0.360960   \n",
       "75%      0.540840    0.541517    0.544342    0.511320    0.503810    0.486232   \n",
       "max      0.991070    0.952930    0.950500    0.998370    0.914860    0.893100   \n",
       "\n",
       "       alpha_ec_6  alpha_ec_7  alpha_ec_8  alpha_ec_9  ...  ratio_theta_39  \\\n",
       "count  180.000000  180.000000  180.000000  180.000000  ...      180.000000   \n",
       "mean     0.363476    0.369076    0.377025    0.384056  ...        1.018505   \n",
       "std      0.186206    0.186509    0.188557    0.195015  ...        0.786103   \n",
       "min      0.058347    0.059784    0.066457    0.065896  ...        0.150610   \n",
       "25%      0.205645    0.216885    0.219768    0.238817  ...        0.567813   \n",
       "50%      0.364725    0.370520    0.370055    0.359725  ...        0.795555   \n",
       "75%      0.484110    0.500715    0.504252    0.519500  ...        1.266450   \n",
       "max      0.881890    0.847760    0.829670    0.987760  ...        6.624000   \n",
       "\n",
       "       ratio_theta_40  ratio_theta_41  ratio_theta_42  ratio_theta_43  \\\n",
       "count      180.000000      180.000000      180.000000      180.000000   \n",
       "mean         0.987059        0.982096        1.037945        0.971646   \n",
       "std          0.748024        0.774820        0.913907        0.782806   \n",
       "min          0.181840        0.156700        0.175150        0.129730   \n",
       "25%          0.544520        0.478085        0.478295        0.502760   \n",
       "50%          0.833965        0.693510        0.788905        0.751085   \n",
       "75%          1.170825        1.161300        1.311050        1.158325   \n",
       "max          6.733600        4.496800        6.669300        5.561000   \n",
       "\n",
       "       ratio_theta_44  ratio_theta_45  ratio_theta_46  ratio_theta_47  \\\n",
       "count      180.000000      180.000000      180.000000      180.000000   \n",
       "mean         0.988384        1.019272        0.969618        1.081742   \n",
       "std          0.736152        0.754223        0.766757        0.683975   \n",
       "min          0.163480        0.221970        0.186500        0.202360   \n",
       "25%          0.500135        0.539732        0.503913        0.619140   \n",
       "50%          0.740230        0.757965        0.733035        0.907780   \n",
       "75%          1.161850        1.202875        1.097800        1.301550   \n",
       "max          3.959300        4.450900        5.353900        5.352300   \n",
       "\n",
       "           labels  \n",
       "count  180.000000  \n",
       "mean     0.444444  \n",
       "std      0.498290  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      1.000000  \n",
       "max      1.000000  \n",
       "\n",
       "[8 rows x 433 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['labels']\n",
    "features = data.drop(columns=['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our dataset\n",
    "features_train, features_test, labels_train, labels_test=train_test_split(features,labels,test_size=0.3)\n",
    "features_train, features_validation, labels_train, labels_validation = train_test_split(features,labels,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential([keras.layers.Dense(20,activation=tf.nn.relu),\n",
    "                        keras.layers.Dense(2,activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.2417 - val_acc: 0.9259\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.2408 - val_acc: 0.9259\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.2404 - val_acc: 0.9259\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.2410 - val_acc: 0.9259\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.2406 - val_acc: 0.9259\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.2411 - val_acc: 0.9259\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.2423 - val_acc: 0.9259\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.2424 - val_acc: 0.9259\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2414 - val_acc: 0.9259\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2423 - val_acc: 0.9259\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.2424 - val_acc: 0.9259\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.2428 - val_acc: 0.9259\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.2445 - val_acc: 0.9259\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.2441 - val_acc: 0.9259\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.2439 - val_acc: 0.9259\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.2429 - val_acc: 0.9259\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.2433 - val_acc: 0.9259\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.2444 - val_acc: 0.9259\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.2440 - val_acc: 0.9259\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.2443 - val_acc: 0.9259\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.2451 - val_acc: 0.9259\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.2446 - val_acc: 0.9259\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.2446 - val_acc: 0.9259\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.2446 - val_acc: 0.9259\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.2463 - val_acc: 0.9259\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.2465 - val_acc: 0.9259\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.2464 - val_acc: 0.9259\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.2463 - val_acc: 0.9259\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2464 - val_acc: 0.9259\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2465 - val_acc: 0.9259\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.2463 - val_acc: 0.9259\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.2465 - val_acc: 0.9259\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.2471 - val_acc: 0.9259\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.2475 - val_acc: 0.9259\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.2473 - val_acc: 0.9259\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.2477 - val_acc: 0.9259\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.2479 - val_acc: 0.9259\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2481 - val_acc: 0.9259\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2490 - val_acc: 0.9259\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2500 - val_acc: 0.9259\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.2492 - val_acc: 0.9259\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.2484 - val_acc: 0.9259\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.2496 - val_acc: 0.9259\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.2500 - val_acc: 0.9259\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.2503 - val_acc: 0.9259\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.2505 - val_acc: 0.9259\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.2519 - val_acc: 0.9259\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.2504 - val_acc: 0.9259\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.2500 - val_acc: 0.9259\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.2521 - val_acc: 0.9259\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(features_train,labels_train,epochs=50, validation_data=(features_validation, labels_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0779 - acc: 0.9815\n",
      "[0.07788969576358795, 0.9814814925193787]\n"
     ]
    }
   ],
   "source": [
    "prediction_features=model.predict(features_test)\n",
    "performance=model.evaluate(features_test,labels_test)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
